#+TITLE: Final Project - DD2412 Advanced Deep Learning

In this project, we are going to reproduce some part of the results from the paper [[Improved Autoregressive Modeling with Distribution Smoothing][https://arxiv.org/abs/2103.15089]] by Meng et al., ICLR 2021.


* TODO
*Dec 2, 2021*
- [ ] Training Stage 1 with no. of ResNet = =5= on KTH Cluster

*Dec 1, 2021*
- [ ] Refactor `CNN_helper` for two stages of the model
- [ ] Do PixelCNN on smooth data, potentially compare with PixelCNN trained on unsmoothed data

- [X] Use MNIST, ACTUALLY USE CIFAR10
- [X] Make function to convolve an image with gaussian noise
  - [X] Can we try this type of convonlution instead? https://scipy-lectures.org/intro/scipy/auto_examples/solutions/plot_image_blur.html

* Random thoughts
- [ ] Read about PixelCNN++. Can we use pre-trained weights?
- [ ] The amount of noise that the paper uses seems insanely high, as seen in =Autoregressive-Modeling-with-Distribution-Smoothing/configs/pixelcnnpp_conditioned_train_cifar10.yml=.
  - The images we generate with that amount of noise do not look like the presented images.

Original paper's repo: https://github.com/chenlin9/Autoregressive-Modeling-with-Distribution-Smoothing

* How to SSH
Create =~/.ssh/config=
=conda activate adlenv=
=/sshx:adlvm:/home/cuong/advdl_project/=
To copy a file: =scp -r adlvm:advdl_project/imgs/ssd.png .=
* Single step denoising
** Notes
https://github.com/Rayhane-mamah/Tacotron-2/issues/155
** Pipeline
1. Train stage 1 on smooth data. This gives $p(\tilde x)$.
2. Sample from stage 1. This returns smooth images with distribution $p(\tilde x)$, and save the images.
3. Do single step denoising

** Single step denoising
\begin{align*}
\bar x = \tilde x + \sigma^2 \nabla_{\tilde x} \log(p_\theta(\tilde x))
\end{align*}
Sampling from stage 1 network gives the image $\tilde x$
The variance $\sigma^2$ is known as a parameter.
$\nabla_{\tilde x} \log(p_\theta(\tilde x))$

* PIPELINE FOR TWO STEP DENOISING
1. Train stage 1 on smooth data. This gives $p(\tilde x)$.
2. Sample from stage 1. This returns smooth images with distribution $p(\tilde x)$, and save the images.
3. Train stage 2. This takes as input smooth images, and is trained to map those to regular images.
4. To get the final output of the network(s). Sample from stage 1 to produce a smooth image. Give that image to stage 2, and stage 2 will denoise that smooth image to produce a regular image.
